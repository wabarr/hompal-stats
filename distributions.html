<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title></title>

<script src="libs/jquery-1.11.3/jquery.min.js"></script>
<script src="libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="libs/tocify-1.9.1/jquery.tocify.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/united.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-57395681-1', 'auto');
  ga('send', 'pageview');

</script>
<link rel="shortcut icon" href="favicon.ico" type="image/x-icon">
<link rel="icon" href="favicon.ico" type="image/x-icon">

<style type="text/css">code{white-space: pre;}</style>
<link rel="stylesheet"
      href="libs/highlight/textmate.css"
      type="text/css" />
<script src="libs/highlight/highlight.js"></script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="octicons/octicons.css" type="text/css" />
<link rel="stylesheet" href="css/custom-style.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<div class="container-fluid main-container">

<!-- tabsets -->
<script src="libs/navigation-1.1/tabsets.js"></script>
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.9em;
  padding-left: 5px;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">



<div id="navbar">
  <div id="navbar-container">
    <ul id="navbar-ul">
      <li><a href="index.html"><span class="mega-octicon octicon-home"></span></a></li>
      <li><a href="datasets.html">Data</a></li>
      <li><a href="schedule.html">Schedule</a></li>
      <li><a href="ANTH6413_syllabus.docx">Syllabus</a></li>
      <li><a href="gettinghelp.html">Getting Help</a></li>
      
    </ul>
  </div>
</div>

<div class="fluid-row" id="header">




</div>


<div id="distributions" class="section level1">
<h1>Distributions</h1>
<div id="random-variables" class="section level2">
<h2>Random Variables</h2>
<p>A <strong><em>random variable</em></strong> –in statistical terms– is a variable whose value depends on random chance. Each random variable has one or more parameters governing the probability of different outcomes. There are two types of random variables: <strong><em>discrete random variables</em></strong> which have a limited number of possible discrete outcomes and <strong><em>continuous random variables</em></strong> which have a (theoretically) unlimited number of possible outcomes.</p>
<div id="challenge" class="section level3">
<h3><span class="mega-octicon octicon-puzzle"></span> Challenge</h3>
<p>Think of two examples of a discrete random variables and two examples of a continuous random variables for your area of scientific interest. What is the sample space for the random variable?</p>
</div>
</div>
<div id="probability-distributions" class="section level2">
<h2>Probability Distributions</h2>
<p>If we plot the values from a random variable using a histogram, we call the result a <strong><em>probability distribution</em></strong>. The various distributions form the basis of parametric statistics. There are four main R functions associated with each probability distribution. In of the below, you will replace <span class="math inline">\(dist\)</span> with the abbreviation for that distribution (norm, binom, etc.)</p>
<ul>
<li>rdist - random values drawn from the <span class="math inline">\(dist\)</span> function</li>
<li>ddist - probability density of <span class="math inline">\(dist\)</span> at a particular point</li>
<li>pdist - cumulative (tail) probability of the <span class="math inline">\(dist\)</span> function</li>
<li>qdist - quantiles of <span class="math inline">\(dist\)</span> (quantiles are the converse of cumulative probability)</li>
</ul>
</div>
<div id="discrete-distributions" class="section level2">
<h2>Discrete Distributions</h2>
<div id="binomial-distribution" class="section level3">
<h3>Binomial Distribution</h3>
<p>A <strong>Bernouili trial</strong> describes an event that has exactly two possible outcomes: success and failure. Success occurs with a given probability, for example <span class="math inline">\(p = 0.2\)</span>. We know how likely a trial is to result in success, but any given trial may result in either success or failure, and this cannot be predicted for a single trial (the outcome is stochastic).</p>
<p>The result of a series of <span class="math inline">\(n\)</span> Bernoulili trials with <span class="math inline">\(X\)</span> successful outcomes results in a binomial random variable.</p>
<p>The expected value of the binomial distribution is <span class="math inline">\(E(x) = np\)</span></p>
<p>Binomial random variables can be simulated in R using the <code>rbinom()</code> function.</p>
<pre class="r"><code># 10 observations, 1 trial
rbinom(n = 10, size=1, prob = 0.5)</code></pre>
<pre><code>##  [1] 1 1 1 0 1 1 0 0 0 1</code></pre>
<pre class="r"><code># 1 observation, 10 trials
rbinom(n = 1, size=10, prob = 0.5)</code></pre>
<pre><code>## [1] 5</code></pre>
<pre class="r"><code># 10 observations, 10 trials
rbinom(n = 10, size=10, prob = 0.5)</code></pre>
<pre><code>##  [1] 4 5 3 5 5 4 4 8 7 5</code></pre>
<p>We can use the <code>dbinom()</code> function to get a sense of the shape of the binomial distribution.</p>
<pre class="r"><code>library(ggplot2)
qplot(x=1:25, y=dbinom(1:25, 25, prob = 0.5), geom=&quot;line&quot;, main=&quot;binomial density prob=0.5&quot;)</code></pre>
<p><img src="distributions_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<pre class="r"><code>qplot(x=1:25, y=dbinom(1:25, 25, prob = 0.2), geom=&quot;line&quot;, main=&quot;binomial density prob=0.2&quot;)</code></pre>
<p><img src="distributions_files/figure-html/unnamed-chunk-2-2.png" width="672" /></p>
<p><strong><em>Notice:</em></strong> the right tail of this distribution is not at zero, but is asymptotically approaching zero.</p>
<pre class="r"><code>dbinom(25, 25, prob = 0.2)</code></pre>
<pre><code>## [1] 3.355443e-18</code></pre>
</div>
<div id="simulation" class="section level3">
<h3>Simulation</h3>
<p>We can also simulating data from a binomial distribution. The graph shows that the most common outcome of 5000 trials of a binomial function with a probability of 0.5 is to have approximately 2500 successful outcomes. It is significantly less likely to get many more or less than 2500 successes. Note: the binomial distribution approximates the normal distribution at very large values of <span class="math inline">\(n\)</span>.</p>
<pre class="r"><code>qplot(rbinom(n = 5000, size=5000, prob = 0.5), main=&quot;binomial distribution p = 0.5&quot;)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="distributions_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
</div>
<div id="poisson-distribution" class="section level3">
<h3>Poisson Distribution</h3>
<p>Is similar to the binomial distribution, but describes rare events, when the number of trials <span class="math inline">\(n\)</span> is unknown. Requires a single rate parameter <span class="math inline">\(\lambda\)</span>. It is commonly pops up when examining the number of events occuring through time (e.g., the number of pieces of mail recieved per day, or the number of speciation events occuring per millenium). The expected value and variance for the Poisson distribution are both equal to lambda</p>
<pre class="r"><code>rpois(10, lambda = 0.2)</code></pre>
<pre><code>##  [1] 0 1 1 0 1 0 0 0 0 0</code></pre>
<pre class="r"><code>qplot(x=0:5, y=dpois(0:5, lambda = 0.2), main=&quot;Poisson distribution with lambda = 0.2&quot;, geom=&quot;line&quot;)</code></pre>
<p><img src="distributions_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p><strong>At large values of lambda, the Poisson distribution looks very much like a normal distribution with mean <span class="math inline">\(\lambda\)</span>.</strong></p>
<pre class="r"><code>qplot(x=1:60, y=dpois(1:60, lambda = 30), main=&quot;Poisson distribution with lambda = 30&quot;, geom=&quot;line&quot;)</code></pre>
<p><img src="distributions_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
</div>
</div>
<div id="continuous-distributions" class="section level2">
<h2>Continuous Distributions</h2>
<div id="uniform-distribution" class="section level3">
<h3>Uniform Distribution</h3>
<p>The uniform distribution represents a function in which the probability density is equal for each sub-interval across the a given range. This results in a flat frequency distribution. The expected value over the range <span class="math inline">\(a\)</span> to <span class="math inline">\(b\)</span> is <span class="math inline">\((a + b)/2\)</span>. An example might be the distribution of trees on a savannah landscape, which are competing with one another for nutrients and light.</p>
<pre class="r"><code>runif(10, min = 1, max = 10)</code></pre>
<pre><code>##  [1] 3.792437 1.555123 8.864378 6.220374 7.035805 5.221383 3.887584
##  [8] 5.675083 7.423624 8.272848</code></pre>
<pre class="r"><code>qplot(runif(10000), min=1, max=10, main=&quot;uniform distribution from 1 to 10&quot;)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="distributions_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
</div>
<div id="normal-distribution" class="section level3">
<h3>Normal Distribution</h3>
<p>The normal distribution (also known as the Gaussian distribution) is the familiar bell-curve shaped distribution that is symmetrical around the mean, with diminishing tails as you move away from the mean. Many phenomena in nature are distributed as a normal distribution, especially continuous measurement values. The normal distribution has two parameters, the mean (<span class="math inline">\(\mu\)</span>) and the standard deviation (<span class="math inline">\(\sigma\)</span>).</p>
<pre class="r"><code>rnorm(10, mean=0, sd=1)</code></pre>
<pre><code>##  [1] -0.21434935  0.91263221  0.36565194  1.21715521 -0.16847692
##  [6] -0.02612499 -0.21441682  1.03811915 -0.17070968 -0.52196410</code></pre>
<pre class="r"><code>qplot(rnorm(10000, mean=0, sd=1), main=&quot;Standard normal distribution &quot;)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="distributions_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
</div>
<div id="log-normal-distribution" class="section level3">
<h3>Log-normal Distribution</h3>
<p>The log-normal distribution resembles a normal distribution when it is logged.</p>
<pre class="r"><code>rlnorm(10, meanlog = 0, sdlog = 1)</code></pre>
<pre><code>##  [1] 1.3282053 0.6510334 0.9151741 0.4400827 1.1056235 1.1189883 2.0316657
##  [8] 1.3781938 0.8125269 0.2251244</code></pre>
<pre class="r"><code>lnorm &lt;- rlnorm(1000, meanlog = 0, sdlog = 1)

qplot(lnorm, main=&quot;lognormal distribution&quot;)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="distributions_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<pre class="r"><code>qplot(log(lnorm), main=&quot;logged lognormal distribution&quot;)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="distributions_files/figure-html/unnamed-chunk-9-2.png" width="672" /></p>
</div>
<div id="exponential-distribution" class="section level3">
<h3>Exponential Distribution</h3>
<p>The exponential distribution is the continuous version of the Poisson distribution. It is goverend by a single rate parameter.</p>
<pre class="r"><code>rexp(10, rate=2)</code></pre>
<pre><code>##  [1] 0.418595441 0.274640016 0.002990006 0.875365764 0.586469403
##  [6] 0.479611487 0.861035218 0.908921648 0.797156793 0.594646006</code></pre>
<pre class="r"><code>exponential &lt;- rexp(1000, rate=2)
qplot(exponential, main=&quot;Shape of Exponential distribution using random simulated data&quot;)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="distributions_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>Alternatively, we can compute the theoretical density values for a sequence of numbers from 0 to 5.</p>
<pre class="r"><code>qplot(seq(0,5,0.1), dexp(x = seq(0,5,0.1), rate=2), geom=&quot;line&quot;, main=&quot;Theoretical shape of exponential dist with rate = 2&quot;)</code></pre>
<p><img src="distributions_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
</div>
<div id="tail-cumulative-probability" class="section level3">
<h3>Tail (cumulative) probability</h3>
<p>It is often very useful to know how much probability density is under a distribution up to a certain point. Consider a normal distribution with a mean of 10 and a standard deviation of 1.5.</p>
<p>We can calculate the cumulative probability up to a value of 5 like this:</p>
<pre class="r"><code>pnorm(q = 5, mean = 10, sd = 1.5)</code></pre>
<pre><code>## [1] 0.0004290603</code></pre>
<p>This tells us that 4.290603310^{-4} is the proportion of values that are less than or equal to 5 in this probability distribution. If we were dealing with real data, we would be forced to say that an observation of 5 is very uncommon in this distribution, and the cumulative probability gives us an estimate of just how unlikely</p>
<p><strong>This is fundamental, as this is exactly what a p value represents, but more on that next week.</strong></p>
<p><span class="mega-octicon octicon-puzzle"></span> Challenge: What is the cumulative probability at a value of 10 in the same normal distribution?</p>
</div>
<div id="quantiles" class="section level3">
<h3>Quantiles</h3>
<p>Quantiles are like cumulative probability turned on its head. Cumulative probabilty asks “how much probability density occurs at less than or equal to a value <span class="math inline">\(x\)</span>”. A quantile is the opposite: “what is the value of <span class="math inline">\(x\)</span> at which a given proportion of the probability density occurs?”</p>
<p>The most familiar examples are percentiles. Take a normal distribution of exam scores.</p>
<pre class="r"><code>set.seed(1237)
grades &lt;- rnorm(1000, mean=75, sd=10)
qplot(grades)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="distributions_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>We might ask where the 90%th percentile is located. At this <span class="math inline">\(x\)</span> value, 90% of observations are less than or equal to <span class="math inline">\(x\)</span>.</p>
<pre class="r"><code>ninety_percentile &lt;- qnorm(0.9, mean=75, sd = 10)
qplot(grades, main=&quot;grades distribution with 90th percentile indicated&quot;) + 
  geom_vline(xintercept=ninety_percentile, color=&quot;red&quot;)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="distributions_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>We can check to see if this matches by counting how many observations are less than or equal to the <code>ninety_percentile</code> calculted from the<code>qnorm()</code> function.</p>
<pre class="r"><code>sum(grades &lt;= ninety_percentile) / length(grades)</code></pre>
<pre><code>## [1] 0.893</code></pre>
<p><span class="mega-octicon octicon-question"></span> Why isn’t this number exactly 0.9?</p>
</div>
<div id="testing-for-normality" class="section level3">
<h3>Testing for normality</h3>
<p>It is often very useful to test an empirical distribution of values to see how closely it approximates a normal distribution. There are two main ways to do this:</p>
<ol style="list-style-type: decimal">
<li>Visually with a Q-Q plot</li>
<li>Statistically with Shapiro-Wilk normality test</li>
</ol>
</div>
<div id="q-q-plot" class="section level3">
<h3>Q-Q plot</h3>
<p>The Q-Q plot compares your empirical cumulative distribution to the theoretical normal cumulative distribution. If the data are normal, then the Q-Q plot will look like a straight line.</p>
<pre class="r"><code>qqnorm(rnorm(1000))</code></pre>
<p><img src="distributions_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p>If your data are not normally distributed, then the Q-Q plot will look curved, or banana shaped. It will take some practice to figure out how far a Q-Q plot can deviate from a straight line without creating too many problems.</p>
<pre class="r"><code>qqnorm(rnorm(1000)^2)</code></pre>
<p><img src="distributions_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<pre class="r"><code>qqnorm(rnorm(1000)^3)</code></pre>
<p><img src="distributions_files/figure-html/unnamed-chunk-17-2.png" width="672" /></p>
</div>
<div id="shapiro-wilks-test-for-normality" class="section level3">
<h3>Shapiro-Wilks test for normality</h3>
<p>The Shapiro-Wilk Test yields a test statistic W, by finding the largest deviation from the expected line in a qqplot. This is a powerful test for normality, but does not work well when there are many ties in the data.</p>
<pre class="r"><code>shapiro.test(rnorm(1000))</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  rnorm(1000)
## W = 0.99704, p-value = 0.0608</code></pre>
<pre class="r"><code>shapiro.test(rnorm(1000)^2)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  rnorm(1000)^2
## W = 0.70506, p-value &lt; 2.2e-16</code></pre>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
