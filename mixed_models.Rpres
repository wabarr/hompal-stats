Linear Mixed Models
========================================================
incremental: true

![mixed](mixed-model.jpg)

Categorical Explanatory Variables
=====================

So far in [ANOVA](anova.html) we have treated all categorical vars as the same

There are actually two types of categorical variables
 
*  ***fixed effects***
*  ***random effects***

## It can be tricky at first to tell them apart

Telling them apart
==================

ANOVA model: $$Y_{ij}=\mu + A_i + \epsilon_{ij}$$

**Fixed effects** ($A_i$) affect the mean of groups in a meaningful way

Mixed Model: $$Y_{ij}=\mu + A_i + U_i + \epsilon_{ij}$$

**Random effects** ($U_i$) further break down the error term, structuring variance, but not in an additive way like fixed effects


Telling them apart
=============

**Fixed Effects**:

*  meaningful factor labels (e.g., male); small possible set
*  affect only mean of $y$ variable
*  effect predictable in different studies (e.g., sex in monkey morphometrics)

**Random Effects**:

*  uninformative factor labels (e.g., site A); very large possible set
*  affect only the variance of $y$ variable
*  effect unpredictable or meaningless across studies

Telling them apart - Example
=============
incremental: false

**Question: do dyadic aggression rates differ by sex?**

You follow a group of habituated monkeys for 2 months. Each day you watch each monkey for an hour, and record the number of agonistic encounters, and the time of day the observation was made.  In the end you have `r 10 * 60` observations (10 monkeys $\times$ 60 days).


MonkeyID | Sex | AggEncounters | ObservationTime
---|----|----|----
Bob | male | 4 | morning
Cindy | female | 3 | morning
Bob | male | 7 | evening
Cindy | female | 2 | evening
... | ... | ... | ...

Telling them apart - Example
=============

MonkeyID | Sex | AggEncounters | ObservationTime
---|----|----|----
Bob | male | 4 | morning
Cindy | female | 3 | morning
Bob | male | 7 | evening
Cindy | female | 2 | evening
... | ... | ... | ...

You have a single response variable: **AggEncounters**

Three predictor variables: **Sex**, **MonkeyID**, **ObservationTime**

**Question: do dyadic aggression rates differ by sex?**

Which are fixed and which are random effects?

Two main circumstances where LMM is first choice
================

*  none of your effects are fixed (less common)
*  you have one or more fixed effects, but also have ***pseudo-replication*** (more common)

Pseudo-replication
==================

Recall from our discussion of ANOVA that independent observations in a treatment group are called ***replicates***

Example: in a study of tooth crown dimensions in hunter-gatherers versus industrialized populations, each measured tooth is a replicate of the population treatment. 

***Pseudoreplication*** occurs when what appear to be a replicate of the treatment group actually isn't independent.  

This situation is common, and is easy to identify with a bit of practice. 

Pseudo-replication
==================

MonkeyID | Sex | AggEncounters | ObservationTime
---|----|----|----
Bob | male | 4 | morning
Cindy | female | 3 | morning
Bob | male | 7 | evening
Cindy | female | 2 | evening
... | ... | ... | ...

Recall our dataset of 600 observations of sex and aggressive encounter rate, measured daily for 2 months (60 days) for 10 individuals.  

**This dataset is massively pseudo-replicated.....why?**

LMM in R
====================

`lme4` package

```{r}
library(lme4)
```

Models are specified much like normal linear models

Random effects are specified as: `(1|randomEffect)`

The 1 stands in for the intercept: effectively, you are saying: "allow each level of `randomEffect` to have its own independent intercept"

Model Simplification
===================
type: section

## "Everything should be kept as simple as possible, but no simpler."

### - Albert Einstein (probably never said this...)

anova() function - new use for old friend 
=======================

Recall that `anova()` doesn't do analysis of variance, it creates an ANOVA table from a model

You can also compare two models with `anova()` to test the hypothesis that they are significantly different

The models are compared with a ***likelihood-ratio test***

likelihood ratio test
===================

Only valid for models that are ***nested***: *i.e., one is a subset of the other*

```{}
simpler  <-    lm(resp ~ fac1 + fac2)
morecomplex <- lm(resp ~ fac1 + fac2 + fac3)
anova(simpler, morecomplex)
```

***Note:*** more complex models *ALWAYS* fit the data better, but likelihood ratio test asks if this difference is significant



Generalized Linear Mixed Models
==================

Like any other linear models, a basic assumption of general linear mixed-models is a normal error term

However, the structure of data may make this assumption invalid (e.g. binary data or count data)

Two very common types of non-normal error structures are:

*  poisson - for count data
*  binomial - for binary (e.g. presence absence data) or proportion data

GLMM in R
==================

```{}
lmer(response ~ fixedEffect + (1|randomEffect), family="poisson")
```
